{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "287e13a6-2318-4ea8-8104-6dd948efd33c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred for URL: https://www.goodreads.com//book/show/617097.Pather_Panchali. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/33917.The_Namesake. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/33917.The_Namesake. Retrying... (2/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/15841419. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/15841419. Retrying... (2/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/10290924. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/10416071. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/13606504. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/13606504. Retrying... (2/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/13425917. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/115030.Chokher_Bali. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/16143698. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/9255439. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/15720202. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/11589378. Retrying... (1/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/11589378. Retrying... (2/3)\n",
      "Timeout occurred for URL: https://www.goodreads.com//book/show/85301.Unaccustomed_Earth. Retrying... (1/3)\n",
      "['Pather Panchali: Song of the Road', 'চাঁদের পাহাড়', 'ব্যোমকেশ সমগ্র', 'The Complete Adventures of Feluda, Vol. 1', 'শঙ্কু সমগ্র', 'Sesher Kobita, the Last Poem', 'আরণ্যক', 'The Namesake', 'টেনিদা সমগ্র', 'The Complete Adventures of Feluda, Vol. 2', 'গল্পগুচ্ছ', 'সেই সময়', 'বিশ্বাসঘাতক', 'Srikanta', 'শঙ্খনীল কারাগার', 'Abol Tabol: The Nonsense World of Sukumar Ray', 'Gora', 'কাবুলিওয়ালা', 'কালবেলা', 'Mother of 1084', 'প্রথম আলো ১', 'দেবী', 'কাকাবাবু সমগ্র ১', 'Devdas', 'গল্প ১০১', 'ময়ূরাক্ষী', 'Chokher Bali', 'Chowringhee', 'পদ্মানদীর মাঝি', 'পুতুলনাচের ইতিকথা', 'Gitanjali', 'Parineeta', 'আদর্শ হিন্দু হোটেল', \"ঠাকু'মার ঝুলি\", 'উত্তরাধিকার', 'কলকাতায় ফেলুদা', 'দীপু নাম্বার টু', 'কালপুরুষ', 'মনোজদের অদ্ভুত বাড়ি', 'হাজার বছর ধরে', 'প্রথম আলো ২', 'নন্দিত নরকে', 'Unaccustomed Earth', 'Interpreter of Maladies', 'নিশীথিনী', 'Anandamath', 'Pather Dabi: The Right of Way', 'দেবী চৌধুরানী', 'দেশে বিদেশে', 'The Home and the World']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Headers to simulate a browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to fetch and parse a URL with retry mechanism\n",
    "def fetch_url(url, retries=3, delay=5):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)  # Set timeout to 10 seconds\n",
    "            response.raise_for_status()  # Raise exception for 4xx/5xx errors\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Extract title\n",
    "            title = soup.find('h1', class_='Text Text__title1').text.strip() if soup.find('h1', class_='Text Text__title1') else 'N/A'\n",
    "            return title  # Return the title if successfully fetched\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Timeout occurred for URL: {url}. Retrying... ({i+1}/{retries})\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break  # For non-timeout errors, break out of the retry loop\n",
    "\n",
    "        time.sleep(delay)  # Delay before retrying\n",
    "\n",
    "    return 'N/A'  # Return 'N/A' if all retries fail\n",
    "\n",
    "# Scrape the main page to get all book URLs\n",
    "master_list = []\n",
    "for i in range(1, 2):  # Assuming you want to scrape only the first page (modify range as needed)\n",
    "    url = f\"https://www.goodreads.com/shelf/show/bengali?page={i}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the book URLs\n",
    "    for x in soup.find_all('a', {\"class\": \"bookTitle\"}):\n",
    "        item = 'https://www.goodreads.com/' + x['href']\n",
    "        master_list.append(item)\n",
    "\n",
    "# List to store book titles\n",
    "master_list2 = []\n",
    "\n",
    "# Loop through the URLs and fetch the title for each book\n",
    "for url in master_list:\n",
    "    title = fetch_url(url)  # Fetch the title using retry mechanism\n",
    "    master_list2.append(title)  # Add the title to the list\n",
    "\n",
    "    time.sleep(1)  # Add delay between requests to avoid overloading the server\n",
    "\n",
    "# Display the results\n",
    "print(master_list2)\n",
    "\n",
    "# Optional: Save the results to a CSV file\n",
    "# df = pd.DataFrame(master_list2, columns=['Book Titles'])\n",
    "# df.to_csv('bengali_books.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79963ac2-e8a0-47ac-a797-1f5778fe0f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(master_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d2bed1-315e-46a8-ab07-38c39a015bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.DataFrame(master_list)\n",
    "# df.to_csv('profile_urls.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be603ee1-13ec-43bf-9a09-95c3a3ec32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in soup.find_all('a',master_list):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28ce3524-3976-4a07-a6b6-17e9eea2df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(master_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b048e-032e-462a-8f04-0f394f7ab80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
